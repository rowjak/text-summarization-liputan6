{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rowjak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rowjak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:25.264578900Z",
     "start_time": "2024-10-08T04:31:24.980714300Z"
    }
   },
   "id": "d547f534281d48e7"
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:25.419674300Z",
     "start_time": "2024-10-08T04:31:25.274818400Z"
    }
   },
   "id": "ac6a9820649a44ef"
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(os.path.join(path, \"dataset/train_combined.parquet\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.447638700Z",
     "start_time": "2024-10-08T04:31:25.333156300Z"
    }
   },
   "id": "9c12ec1a5c948738"
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "# df_test = pd.read_parquet(os.path.join(path, \"dataset/test_combined.parquet\"))\n",
    "# df_dev = pd.read_parquet(os.path.join(path, \"dataset/dev_combined.parquet\"))\n",
    "# df_train_sample = pd.read_parquet(os.path.join(path, \"dataset/train_sample_combined.parquet\"))\n",
    "# df_xtreme_dev = pd.read_parquet(os.path.join(path, \"dataset/xtreme_dev_combined.parquet\"))\n",
    "# df_xtreme_test = pd.read_parquet(os.path.join(path, \"dataset/xtreme_test_combined.parquet\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.463370600Z",
     "start_time": "2024-10-08T04:31:44.450916800Z"
    }
   },
   "id": "21b0ca03b98158f1"
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "# df_train.info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.495182800Z",
     "start_time": "2024-10-08T04:31:44.464467500Z"
    }
   },
   "id": "e0dd043fb406e969"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Dataset yang digunaakn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f86691d457e7ea3"
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "def extract_article(sentences):\n",
    "    # Gabungkan array kata-kata menjadi kalimat\n",
    "    text = ' '.join([' '.join(sentence) for sentence in sentences])\n",
    "    # Hilangkan spasi sebelum tanda baca seperti .,;:!?()\n",
    "    text = re.sub(r'\\s+([.,:;!?()])', r'\\1', text)\n",
    "    # Hilangkan spasi setelah tanda baca '.' jika huruf setelahnya kecil\n",
    "    text = re.sub(r'\\.\\s+([a-z])', r'.\\1', text)\n",
    "    text = re.sub(r'\\(\\s+', '(', text)  # Hilangkan spasi setelah '('\n",
    "    text = re.sub(r'\\s+\\)', ')', text)  # Hilangkan spasi sebelum ')'\n",
    "    text = re.sub(r'\\[\\s+', '[', text)  # Hilangkan spasi setelah '['\n",
    "    text = re.sub(r'\\s+\\]', ']', text)  # Hilangkan spasi sebelum ']'\n",
    "    return text\n",
    "\n",
    "def extract_sentences_from_index(clean_article, extractive_summary):\n",
    "    return [clean_article[i] for i in extractive_summary]\n",
    "\n",
    "def convert_time_to_minutes(waktu):\n",
    "    waktu = re.sub(r'\\s*WIB|\\s*WIT|\\s*WITA', '', waktu)\n",
    "    time_obj = pd.to_datetime(waktu, format='%H:%M')\n",
    "    return time_obj.hour * 60 + time_obj.minute\n",
    "\n",
    "def preprocessing_article(text):\n",
    "    # ubah semua menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    # ubah kata yang berulang (dengan tanda penghubung) menjadi terpisah\n",
    "    text = re.sub(r'\\b(\\w+)-\\1\\b', r'\\1 \\1', text)\n",
    "    # hilangkan teks yang memiliki tanda kurun () dan []\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # hilangkan awalan liputan6.com kemudian setelah itu tanda :\n",
    "    text = re.sub(r'^liputan6\\.com, [^:]+: ', '', text)\n",
    "    # hilangkan semua tanda baca\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # hilangkan spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = re.sub(r'\\b\\d{1,2}:\\d{2}\\s?(WIB|WIT|WITA)?\\b', '', text)\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.512666Z",
     "start_time": "2024-10-08T04:31:44.489504300Z"
    }
   },
   "id": "5b288cd1b7d52898"
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "def save_preprocessing(df_used, df_save_path):\n",
    "    df_used['ext_clean_article'] = df_used['clean_article'].apply(extract_article)\n",
    "    df_used['ext_clean_summary'] = df_used['clean_summary'].apply(extract_article)\n",
    "    df_used['extractive_summary_sentences'] = df_used.apply(lambda row: extract_sentences_from_index(row['clean_article'], row['extractive_summary']), axis=1)\n",
    "    df_used['ext_extractive_summary'] = df_used['extractive_summary_sentences'].apply(extract_article)\n",
    "    df_used['prep_clean_article'] = df_used['ext_clean_article'].apply(preprocessing_article)\n",
    "    df_used['prep_clean_summary'] = df_used['ext_clean_summary'].apply(preprocessing_article)\n",
    "    df_used['prep_extractive_summary'] = df_used['ext_extractive_summary'].apply(preprocessing_article)\n",
    "    df_used['prep_clean_article_no_sw'] = df_used['prep_clean_article'].apply(remove_stopwords)\n",
    "    df_used.to_parquet(df_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.537681700Z",
     "start_time": "2024-10-08T04:31:44.517173200Z"
    }
   },
   "id": "640a0bf4aff74057"
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "# save_preprocessing(df_test,\"dataset/used/test_prep.parquet\")\n",
    "# save_preprocessing(df_dev,\"dataset/used/dev_prep.parquet\")\n",
    "# save_preprocessing(df_xtreme_dev,\"dataset/used/xtreme_dev_prep.parquet\")\n",
    "# save_preprocessing(df_xtreme_test,\"dataset/used/xtreme_test_prep.parquet\")\n",
    "# save_preprocessing(df_train_sample,\"dataset/used/train_sample_prep.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:31:44.550314Z",
     "start_time": "2024-10-08T04:31:44.529811900Z"
    }
   },
   "id": "fdb7b7fc5dd6e535"
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "save_preprocessing(df_train,\"dataset/used/train.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T04:36:55.915120100Z",
     "start_time": "2024-10-08T04:31:44.545697400Z"
    }
   },
   "id": "7700d3719084fd9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
